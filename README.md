# Data Engineering

This project is again a fictional case study. You have been hires as a Junior Data Engineer for a company that develops e-scooter sharing systems. They have noticed that it is of big interest to them to havint the scooters parked where users need them. Some requirements could be:
 - When it starts raining, more people use e-scooters.
 - In hilly areas, people use e-scooters to get up the hill but then walk down.
 - Tourists, that arrived with cheap flights, are a big potentioal group of users, but they mostly need the scooters neara touristic attractions.

Your task will now be to collect data from external sources and store it appropriatly so that in the future predictive models can be created. 

## Which tools to use?

### 1. Web Scraping data from Wikipedia
   
### 2. Collect data with API's
### 3. Create database (MySQL)
   In order to store the data, we need to create a database. The MySQL needs then to be hosted in the cloud, so it can fetch all the data from 
### 4. Set up and automate a cloud pipeline




If you want to read more about how to web scrape Wikipedia tables, check out my [Medium article](https://medium.com/@oboenfreak/web-scraping-wikipedia-tables-with-python-22223f761b1e) on this subject.
